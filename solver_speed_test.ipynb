{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "12937ad3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Solver-Only Benchmark ---\n",
      "Using device: cuda\n",
      "Total samples per run: 100,000\n",
      "Testing batch sizes: [10000, 25000, 50000, 100000]\n",
      "------------------------------\n",
      "Using device: cuda\n",
      "Pre-building input data template...\n",
      "Template built for max batch size 100000.\n",
      "\n",
      "--- Starting Benchmark ---\n",
      "Batch Size   | Samples/Sec     | Total Time (s)  | Total Samples  \n",
      "----------------------------------------------------------\n",
      "  Testing 100,000 samples in 10 batches of 10000...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 168\u001b[39m\n\u001b[32m    165\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m-\u001b[39m\u001b[33m\"\u001b[39m * \u001b[32m58\u001b[39m)\n\u001b[32m    167\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m bs \u001b[38;5;129;01min\u001b[39;00m BATCH_SIZES_TO_TEST:\n\u001b[32m--> \u001b[39m\u001b[32m168\u001b[39m     sps, total_time, actual_samples = \u001b[43mrun_benchmark\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    170\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m sps == -\u001b[32m1.0\u001b[39m: \u001b[38;5;66;03m# OOM Error\u001b[39;00m\n\u001b[32m    171\u001b[39m         \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbs\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m<12\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m | \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m--- OOM ---\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m<15\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m | \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m--- OOM ---\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m<15\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m | \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m--- OOM ---\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m<15\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 139\u001b[39m, in \u001b[36mrun_benchmark\u001b[39m\u001b[34m(batch_size)\u001b[39m\n\u001b[32m    135\u001b[39m start_time = time.perf_counter()\n\u001b[32m    137\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_batches):\n\u001b[32m    138\u001b[39m     \u001b[38;5;66;03m# *** THIS IS THE ONLY THING BEING TIMED ***\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m139\u001b[39m     _ = \u001b[43msolver\u001b[49m\u001b[43m.\u001b[49m\u001b[43msolve\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mbatch_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconv_bc_outer\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mdirichlet\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43massert_conservation\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mDTYPE\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    141\u001b[39m \u001b[38;5;66;03m# IMPORTANT: Wait for all CUDA kernels to finish\u001b[39;00m\n\u001b[32m    142\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m device.type == \u001b[33m'\u001b[39m\u001b[33mcuda\u001b[39m\u001b[33m'\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Owner\\ProjBeta\\AllCode.py:299\u001b[39m, in \u001b[36mSolverV2_opt.solve\u001b[39m\u001b[34m(self, rho, time, SR, ST, D, V, N0, A, conv_bc_outer, assert_conservation, dtype)\u001b[39m\n\u001b[32m    296\u001b[39m         RHS = N[:, :, n-\u001b[32m1\u001b[39m] + dt*(\u001b[38;5;28mself\u001b[39m._apply_tridiag(Da_oth, Db_oth, Dc_oth, N[:, :, n-\u001b[32m1\u001b[39m]) + \u001b[38;5;28mself\u001b[39m._apply_tridiag(Ca_tha, Cb_tha, Cc_tha, N[:, :, n-\u001b[32m1\u001b[39m]) + S_mid + RHS_bc)\n\u001b[32m    298\u001b[39m     \u001b[38;5;66;03m#Solve\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m299\u001b[39m     N[:, :, n] = \u001b[38;5;28mself\u001b[39m._thomas_batched(LHS_a, LHS_b, LHS_c, RHS)\n\u001b[32m    301\u001b[39m \u001b[38;5;66;03m#Validate conservation on diffusion interiors\u001b[39;00m\n\u001b[32m    302\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m assert_conservation:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import time\n",
    "import math\n",
    "from typing import List, Dict\n",
    "\n",
    "# --- Import from your project files ---\n",
    "try:\n",
    "    from AllCode import ParamDef, ParamSpace\n",
    "    from AllCode import SceneBuilder\n",
    "    from AllCode import SolverV2_opt\n",
    "except ImportError as e:\n",
    "    print(f\"Error: Could not import project files. Make sure .py files are in the same directory.\")\n",
    "    print(f\"Details: {e}\")\n",
    "    exit()\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# --- Hyperparameters for the Benchmark ---\n",
    "\n",
    "# Total number of samples to solve (set high enough for a good measurement)\n",
    "TOTAL_SAMPLES = 100_000\n",
    "\n",
    "# Batch sizes to test. The solver may run out of memory on larger batches.\n",
    "BATCH_SIZES_TO_TEST = [10_000, 25_000, 50_000, 100_000]\n",
    "\n",
    "# --- Global Setup (mimicking your main script) ---\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "DTYPE = torch.float32\n",
    "print(f\"--- Solver-Only Benchmark ---\")\n",
    "print(f\"Using device: {device}\")\n",
    "print(f\"Total samples per run: {TOTAL_SAMPLES:,}\")\n",
    "print(f\"Testing batch sizes: {BATCH_SIZES_TO_TEST}\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "# --- 1. Define the Parameter Space (Must match build_scene.py) ---\n",
    "space = ParamSpace([\n",
    "    #Spatial Source\n",
    "\tParamDef(name=\"A_SR\",       low=0.5e23,     high=3e23,          scale=\"linear\"), # DONE\n",
    "\tParamDef(name=\"Rc_SR\",      low=0.85,       high=1.10,          scale=\"linear\"), # DONE\n",
    "\tParamDef(name=\"o_SR\",       low=0.05,       high=0.20,          scale=\"linear\"), # DONE\n",
    " \n",
    "\t#Temporal Source\n",
    "\tParamDef(name=\"A_ST\",       low=0,          high=0.25,          scale=\"linear\"), # DONE\n",
    "\tParamDef(name=\"f_ST\",       low=0.1,        high=10,          scale=\"log10\"), # DONE\n",
    "\tParamDef(name=\"p_ST\",       low=0,          high=2*math.pi,          scale=\"linear\"), # DONE\n",
    " \n",
    "\t#Diffusion Profile\n",
    "\tParamDef(name=\"A_D\",        low=1,          high=10,          scale=\"log10\"), # DONE\n",
    "\tParamDef(name=\"AL_D\",       low=0.20,       high=1.00,          scale=\"linear\"), # DONE\n",
    "\tParamDef(name=\"A0_D\",       low=0.01,       high=0.20,          scale=\"linear\"), # DONE\n",
    "\tParamDef(name=\"Rc_D\",       low=0.85,       high=1.10,          scale=\"linear\"), # DONE\n",
    "\tParamDef(name=\"RwL_D\",      low=0.025,      high=0.200,          scale=\"linear\"), # DONE\n",
    "\tParamDef(name=\"RwR_D\",      low=0.025,      high=0.200,          scale=\"linear\"), # DONE\n",
    " \n",
    " \t#Convection Profile\n",
    "\tParamDef(name=\"A_V\",        low=0.5,        high=7.5,          scale=\"linear\"), # DONE\n",
    "\tParamDef(name=\"A1_V\",       low=0.10,       high=0.45,          scale=\"linear\"), # DONE\n",
    "\tParamDef(name=\"A2_V\",       low=0.25,       high=3.00,          scale=\"linear\"), # DONE\n",
    "\tParamDef(name=\"R1_V\",       low=0.35,       high=0.60,          scale=\"linear\"), # DONE\n",
    "\tParamDef(name=\"R2_V\",       low=0.65,       high=0.85,          scale=\"linear\"), # DONE\n",
    "\tParamDef(name=\"R3_V\",       low=0.95,       high=1.15,          scale=\"linear\"), # DONE\n",
    "\tParamDef(name=\"Flip_V\",     low=-1.0,       high=1.0,          scale=\"linear\"), # DONE\n",
    "\tParamDef(name=\"Bounce_V\",   low=-1.0,       high=1.0,          scale=\"linear\"), # DONE\n",
    " \n",
    "\t#Initial Density Profile\n",
    "\tParamDef(name=\"A_N0\",       low=5.5e19,     high=9e19,          scale=\"linear\"), # DONE\n",
    "\tParamDef(name=\"Xs_N0\",      low=0.85,       high=1.10,          scale=\"linear\"), # DONE\n",
    "\tParamDef(name=\"H_N0\",       low=0.006,      high=0.018,          scale=\"linear\"), # DONE\n",
    "\tParamDef(name=\"a_N0\",       low=0.006,      high=0.016,          scale=\"linear\"), # DONE\n",
    "\tParamDef(name=\"B_N0\",       low=0.85e20,    high=1.20e20,          scale=\"linear\"), # DONE\n",
    " \n",
    " \t#Edge Boundary Condition\n",
    "\tParamDef(name=\"A_mag\",      low=1e18,       high=1e22,          scale=\"log10\"), # DONE\n",
    "    ParamDef(name=\"A_sign\",     low=-1.0,       high=1.0,          scale=\"linear\"), # DONE\n",
    "])\n",
    "\n",
    "# --- 2. Set up Grids, Builder, and Solver ---\n",
    "rho_grid = torch.linspace(1e-3, 1.2, steps=151, device=device, dtype=DTYPE) #601\n",
    "time_grid = torch.linspace(1e-3, 0.065317, steps=161, device=device, dtype=DTYPE) #641\n",
    "\n",
    "builder = SceneBuilder(rho=rho_grid, time=time_grid)\n",
    "solver = SolverV2_opt()\n",
    "\n",
    "# --- 3. Pre-build Input Data (NOT TIMED) ---\n",
    "print(\"Pre-building input data template...\")\n",
    "try:\n",
    "    # We will build one \"template\" batch based on the largest size\n",
    "    MAX_BATCH_SIZE = max(BATCH_SIZES_TO_TEST)\n",
    "    \n",
    "    # Create stable, \"mean\" parameters (unit-space 0.5)\n",
    "    U_mean = torch.full((1, space.dim), 0.5, device=device, dtype=DTYPE)\n",
    "    X_phys_mean = space.unit_to_phys(U_mean)\n",
    "    plist_mean = space.dict_from_vector(X_phys_mean[0])\n",
    "    \n",
    "    # Create a list of identical parameters\n",
    "    plist_template = [plist_mean] * MAX_BATCH_SIZE\n",
    "    \n",
    "    # Build the *input* to the solver\n",
    "    # This `case_template` dict contains all tensors the solver needs\n",
    "    case_template = builder.build_batch(plist_template)\n",
    "    print(f\"Template built for max batch size {MAX_BATCH_SIZE}.\")\n",
    "\n",
    "except torch.cuda.OutOfMemoryError:\n",
    "    print(f\"ERROR: CUDA Out of Memory just trying to *build* the template batch of size {MAX_BATCH_SIZE}.\")\n",
    "    print(\"Try reducing the largest batch size in BATCH_SIZES_TO_TEST.\")\n",
    "    exit()\n",
    "except Exception as e:\n",
    "    print(f\"Error during pre-build: {e}\")\n",
    "    exit()\n",
    "\n",
    "def run_benchmark(batch_size: int) -> float:\n",
    "    \"\"\"\n",
    "    Runs a benchmark for a given batch size and returns samples per second.\n",
    "    \"\"\"\n",
    "    num_batches = math.ceil(TOTAL_SAMPLES / batch_size)\n",
    "    actual_samples = num_batches * batch_size\n",
    "    \n",
    "    print(f\"  Testing {actual_samples:,} samples in {num_batches} batches of {batch_size}...\")\n",
    "    \n",
    "    try:\n",
    "        # --- 1. Get the input slice for this batch size ---\n",
    "        # This is just a view, very fast, not timed.\n",
    "        batch_input = {k: v[:batch_size] for k, v in case_template.items()}\n",
    "        \n",
    "        # --- 2. Warmup Run ---\n",
    "        # Run the solver once to compile JIT, warm up CUDA, etc.\n",
    "        _ = solver.solve(**batch_input, conv_bc_outer='dirichlet', assert_conservation=False, dtype=DTYPE)\n",
    "        \n",
    "        # Wait for CUDA to finish the warmup\n",
    "        if device.type == 'cuda':\n",
    "            torch.cuda.synchronize()\n",
    "            \n",
    "        # --- 3. Timed Run ---\n",
    "        start_time = time.perf_counter()\n",
    "        \n",
    "        for _ in range(num_batches):\n",
    "            # *** THIS IS THE ONLY THING BEING TIMED ***\n",
    "            _ = solver.solve(**batch_input, conv_bc_outer='dirichlet', assert_conservation=False, dtype=DTYPE)\n",
    "\n",
    "        # IMPORTANT: Wait for all CUDA kernels to finish\n",
    "        if device.type == 'cuda':\n",
    "            torch.cuda.synchronize()\n",
    "            \n",
    "        end_time = time.perf_counter()\n",
    "        \n",
    "        # --- 4. Calculate Results ---\n",
    "        total_time = end_time - start_time\n",
    "        sps = actual_samples / total_time\n",
    "        return sps, total_time, actual_samples\n",
    "\n",
    "    except torch.cuda.OutOfMemoryError:\n",
    "        print(f\"  ERROR: CUDA Out of Memory with batch size {batch_size}. Stopping.\")\n",
    "        return -1.0, -1.0, -1.0\n",
    "    except Exception as e:\n",
    "        print(f\"  ERROR: An exception occurred: {e}\")\n",
    "        return -1.0, -1.0, -1.0\n",
    "\n",
    "# --- Main Execution ---\n",
    "if __name__ == \"__main__\":\n",
    "    results = []\n",
    "    \n",
    "    print(\"\\n--- Starting Benchmark ---\")\n",
    "    print(f\"{'Batch Size':<12} | {'Samples/Sec':<15} | {'Total Time (s)':<15} | {'Total Samples':<15}\")\n",
    "    print(\"-\" * 58)\n",
    "\n",
    "    for bs in BATCH_SIZES_TO_TEST:\n",
    "        sps, total_time, actual_samples = run_benchmark(bs)\n",
    "        \n",
    "        if sps == -1.0: # OOM Error\n",
    "            print(f\"{bs:<12} | {'--- OOM ---':<15} | {'--- OOM ---':<15} | {'--- OOM ---':<15}\")\n",
    "            break\n",
    "        \n",
    "        results.append((bs, sps))\n",
    "        print(f\"{bs:<12} | {sps:<15.2f} | {total_time:<15.4f} | {actual_samples:<15,}\")\n",
    "\n",
    "    # --- Final Report ---\n",
    "    if results:\n",
    "        best_bs, best_sps = max(results, key=lambda item: item[1])\n",
    "        print(\"\\n--- Benchmark Complete ---\")\n",
    "        print(f\"Optimal Batch Size: {best_bs}\")\n",
    "        print(f\"   Max Throughput: {best_sps:,.2f} Samples/Sec\")\n",
    "        \n",
    "        # Compare to your 300k/min baseline (5,000 sps)\n",
    "        baseline_sps = 300_000 / 60\n",
    "        improvement = (best_sps - baseline_sps) / baseline_sps\n",
    "        print(f\"  vs. 5,000 SPS: {improvement:+.1%}\")\n",
    "    else:\n",
    "        print(\"\\n--- Benchmark Failed ---\")\n",
    "        print(\"No valid results were recorded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4397035",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
